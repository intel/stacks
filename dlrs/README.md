## Deep Learning Reference Stack (DLRS)

[![DLRS docker image](https://images.microbadger.com/badges/image/clearlinux/stacks-dlrs-mkl.svg)](https://microbadger.com/images/clearlinux/stacks-dlrs-mkl "DLRS docker image")

### About

The Deep Learning Reference Stack, is an integrated, highly-performant open source stack optimized for Intel® Xeon® Scalable platforms. 

<img src="https://clearlinux.org/sites/default/files/single_2.png" width="400" height="300" />

This open source community release is part of an effort to ensure AI developers have easy access to all features and functionality of Intel platforms.To offer more flexibility, there are multiple versions of the Deep Learning Reference Stack:

* [Tensorflow 1.15 with Intel® Deep Neural Networks Library (Intel® DNNL) primitives, AVX-512 Deep Learning Boost and OpenVINO™ - Deep Learning Deployment Toolkit v2019_R3 (OMP)](https://hub.docker.com/r/clearlinux/stacks-dlrs-mkl)
* [Tensorflow 2.0 with Intel® Deep Neural Networks Library (Intel® DNNL) primitives, AVX-512 Deep Learning Boost and OpenVINO™ - Deep Learning Deployment Toolkit v2019_R3 (TBB)](https://hub.docker.com/r/clearlinux/stacks-dlrs_2-mkl)
* [TensorFlow with Eigen optimized for Intel Architecture](https://hub.docker.com/r/clearlinux/stacks-dlrs-oss)
* [PyTorch DLRS Docker image with Intel® Math Kernel Library and Intel® Deep Neural Networks Library (Intel® DNNL)](https://hub.docker.com/r/clearlinux/stacks-pytorch-mkl)
* [PyTorch DLRS Docker image with Eigen and OpenBLAS](https://hub.docker.com/r/clearlinux/stacks-pytorch-oss)
* [Deep Learning Compiler with TVM and Intel® Math Kernel Library](https://hub.docker.com/r/clearlinux/stacks-ml-compiler)


Please see the folders in this level about the variants and how to build and use them.
