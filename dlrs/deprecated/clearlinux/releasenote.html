<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Deep Learning Reference Stack Release Notes &mdash; System Stacks for Linux* OS  documentation</title>
      <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../../../_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="../../../_static/tabs.css" type="text/css" />
      <link rel="stylesheet" href="../../../_static/css/custom.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../../../" id="documentation_options" src="../../../_static/documentation_options.js"></script>
        <script src="../../../_static/jquery.js"></script>
        <script src="../../../_static/underscore.js"></script>
        <script src="../../../_static/doctools.js"></script>
    <script src="../../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />
    <link href="../../../_static/css/custom.css" rel="stylesheet" type="text/css">

</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../../../index.html" class="icon icon-home"> System Stacks for Linux* OS
            <img src="../../../_static/stacks_logo.png" class="logo" alt="Logo"/>
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul>
<li class="toctree-l1"><a class="reference internal" href="../../../README.html">Stacks containers have been deprecated and please switch to oneapi based containers, you can find oneapi containers at this link :  https://hub.docker.com/u/intel</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../README.html#system-stacks-for-linux-os">System Stacks for Linux* OS</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../README.html#contributing">Contributing</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../README.html#security-issues">Security Issues</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../README.html#mailing-list">Mailing List</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../index.html">Deep Learning Reference Stack</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../index.html#dlrs-release-announcement-and-performance-reports">DLRS Release Announcement and Performance Reports</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../index.html#dlrs-guides">DLRS Guides</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../dlrs.html">Deep Learning Reference Stack Guide</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../dlrs.html#overview">Overview</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../dlrs.html#releases">Releases</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../dlrs.html#tensorflow-single-and-multi-node-benchmarks">TensorFlow single and multi-node benchmarks</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../dlrs.html#pytorch-single-and-multi-node-benchmarks">PyTorch single and multi-node benchmarks</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../dlrs.html#tensorflow-training-tfjob-with-kubeflow-and-dlrs">TensorFlow Training (TFJob) with Kubeflow and DLRS</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../dlrs.html#pytorch-training-pytorch-job-with-kubeflow-and-dlrs">PyTorch Training (PyTorch Job) with Kubeflow and DLRS</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../dlrs.html#working-with-horovod-and-openmpi">Working with Horovod* and OpenMPI*</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../dlrs.html#using-transformers-for-natural-language-processing">Using Transformers* for Natural Language Processing</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../dlrs.html#using-the-openvino-model-optimizer">Using the OpenVINO™ Model Optimizer</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../dlrs.html#using-the-openvino-toolkit-inference-engine">Using the OpenVINO™ toolkit Inference Engine</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../dlrs.html#using-seldon-and-openvino-model-server-with-the-deep-learning-reference-stack">Using Seldon and OpenVINO™ model server with the Deep Learning Reference Stack</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../dlrs.html#use-jupyter-notebook">Use Jupyter Notebook</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../dlrs.html#uninstallation">Uninstallation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../dlrs.html#compiling-aixprt-with-openmp-on-dlrs">Compiling AIXPRT with OpenMP on DLRS</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../dlrs.html#using-the-intel-vtune-profiler-with-dlrs-containers">Using the Intel® VTune™ Profiler with DLRS Containers</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../dlrs.html#related-resources">Related Resources</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../bert-performance.html">State-of-the-art BERT Fine-tune training and Inference</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../bert-performance.html#overview">Overview</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../bert-performance.html#recommended-hardware">Recommended Hardware</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../bert-performance.html#required-software">Required Software</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../bert-performance.html#steps">Steps</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../bert-performance.html#run-bert-fine-tune-training-with-the-squad-1-1-data-set">Run BERT Fine-tune training with the Squad 1.1 data set</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../bert-performance.html#notices-and-disclaimers">NOTICES AND DISCLAIMERS</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../index.html#dlrs-releases">DLRS Releases</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../index.html#dlrs-with-tensorflow">DLRS with TensorFlow*</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../tensorflow/README.html">Deep Learning Reference Stack with Tensorflow and Intel® oneAPI Deep Neural Network Library (oneDNN)</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../index.html#dlrs-with-tensorflow-serving">DLRS with TensorFlow Serving*</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../serving/README.html">Build instructions</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../index.html#dlrs-with-pytorch">DLRS with PyTorch*</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../pytorch/README.html">Deep Learning Reference Stack with Pytorch and Intel® oneAPI Deep Neural Network Library (oneDNN)</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../index.html#dlrs-ml-compiler">DLRS ML Compiler</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../ml-compiler/README.html">Stacks Deep Learning Compiler</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../dsrs/index.html">Data Services Reference Stack</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../dsrs/index.html#overview">Overview</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../dsrs/README.html">Data Services Reference Stack (DSRS) Overview</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../dsrs/terms_of_use.html">Data Services Reference Stack Terms of Use</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../dsrs/index.html#memcached-versions">memcached* versions</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../dsrs/memcached/README.html">Data Services Reference Stack(DSRS) - Memcached*</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../dsrs/index.html#redis-versions">Redis* versions</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../dsrs/redis/README.html">Data Services Reference Stack(DSRS) - Redis*</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../mers/index.html">Media Reference Stack</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../mers/index.html#overview">Overview</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../mers/README.html">Media Reference Stack</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../mers/README.html#mers-on-intel-onecontainer-portal">MeRS on Intel® oneContainer Portal</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../mers/README.html#source-code">Source Code</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../mers/README.html#reporting-security-issues">Reporting Security Issues</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../mers/README.html#supported-platforms-and-media-codecs">Supported Platforms and Media Codecs</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../mers/releasenotes.html">Media Reference Stack Release Notes</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../mers/releasenotes.html#the-media-reference-stack">The Media Reference Stack</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../mers/releasenotes.html#licensing">Licensing</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../mers/releasenotes.html#the-media-reference-stack-licenses">The Media Reference Stack licenses</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../mers/releasenotes.html#disclaimer">Disclaimer</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../mers/releasenotes.html#source-code">Source code</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../mers/releasenotes.html#contributing-to-the-media-reference-stack">Contributing to the Media Reference Stack</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../mers/releasenotes.html#reporting-security-issues">Reporting Security Issues</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../mers/terms_of_use.html">Media Reference Stack Terms of Use</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../mers/CONTRIBUTING.html">Contributing</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../mers/CONTRIBUTING.html#pull-request-process">Pull Request Process</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../mers/CONTRIBUTING.html#code-of-conduct">Code of Conduct</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../mers/AUTHORS.html">Media Reference Stack Authors</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../mers/LICENSES.html">Licenses</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../mers/LICENSES.html#mers-licenses">MeRS licenses</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../mers/LICENSES.html#disclaimer">Disclaimer</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../mers/index.html#guide">Guide</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../mers/mers.html">Media Reference Stack Guide</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../mers/mers.html#overview">Overview</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../mers/mers.html#releases">Releases</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../mers/mers.html#get-the-pre-built-mers-container-image">Get the pre-built MeRS container image</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../mers/mers.html#build-the-mers-container-image-from-source">Build the MeRS container image from source</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../mers/mers.html#use-the-mers-container-image">Use the MeRS container image</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../mers/mers.html#add-aom-support">Add AOM support</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../mers/index.html#ubuntu-releases">Ubuntu* Releases</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../mers/ubuntu/INSTALL.html">Media Reference Stack - Ubuntu*</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../mers/ubuntu/INSTALL.html#building-container-image">Building container image</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../mers/ubuntu/INSTALL.html#getting-mers-pre-built-image">Getting MeRS pre-built image</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../mers/ubuntu/INSTALL.html#running-the-media-container">Running the Media Container</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../mers/ubuntu/INSTALL.html#run-examples">Run examples</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../mers/ubuntu/INSTALL.html#reporting-security-issues">Reporting Security Issues</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../mers/ubuntu/INSTALL.html#legal-notice">LEGAL NOTICE</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../mers/NEWS.html">Changes for <code class="docutils literal notranslate"><span class="pre">v0.4.0</span></code> :</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../mers/NEWS.html#changes-for-v0-3-0">Changes for <code class="docutils literal notranslate"><span class="pre">v0.3.0</span></code> :</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../mers/NEWS.html#changes-for-v0-2-0">Changes for <code class="docutils literal notranslate"><span class="pre">v0.2.0</span></code> :</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../mers/NEWS.html#changes-for-v0-1-0">Changes for <code class="docutils literal notranslate"><span class="pre">v0.1.0</span></code> :</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../mers/BUGS.html">Known Issues</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../mers/BUGS.html#mers-v0-4-0">MeRS <code class="docutils literal notranslate"><span class="pre">v0.4.0</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../mers/BUGS.html#mers-v0-3-0">MeRS <code class="docutils literal notranslate"><span class="pre">v0.3.0</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../mers/BUGS.html#mers-v0-2-0">MeRS <code class="docutils literal notranslate"><span class="pre">v0.2.0</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../mers/BUGS.html#mers-v0-1-0">MeRS <code class="docutils literal notranslate"><span class="pre">v0.1.0</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../mers/CHANGELOG.html">0.4.0 (2021-04-19)</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../mers/CHANGELOG.html#functionality-changes">Functionality Changes</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../mers/CHANGELOG.html#deprecated-features">Deprecated Features</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../mers/CHANGELOG.html#new-features">New Features</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../mers/CHANGELOG.html#refactors">Refactors</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../mers/CHANGELOG.html#changelog-v0-3-0-2020-11-18">Changelog v0.3.0 (2020-11-18)</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../mers/CHANGELOG.html#id2">Functionality Changes</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../mers/CHANGELOG.html#chores">Chores</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../mers/CHANGELOG.html#documentation-changes">Documentation Changes</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../mers/CHANGELOG.html#id3">New Features</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../mers/CHANGELOG.html#bug-fixes">Bug Fixes</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../mers/CHANGELOG.html#id4">Refactors</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../mers/CHANGELOG.html#removed-features">Removed Features</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../mers/CHANGELOG.html#security">Security</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../mers/CHANGELOG.html#id5">0.2.0 (2020-04-14)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../mers/CHANGELOG.html#id6">0.1.0 (2019-10-31)</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../mers/index.html#deprecated-releases">Deprecated Releases</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../mers/deprecated/clearlinux/INSTALL.html">Media Reference Stack - Clear Linux* OS</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../mers/deprecated/clearlinux/INSTALL.html#building-locally">Building Locally</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../mers/deprecated/clearlinux/INSTALL.html#pulling-from-docker-hub">Pulling from Docker Hub</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../mers/deprecated/clearlinux/INSTALL.html#running-the-media-container">Running the Media Container</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../mers/deprecated/clearlinux/INSTALL.html#run-examples">Run examples</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../hpcrs/index.html">High Performance Computing Reference Stack</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../hpcrs/index.html#overview">Overview</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../hpcrs/README.html">High Performance Compute Reference Stack</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../hpcrs/README.html#overview">Overview</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../hpcrs/README.html#releases">Releases</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../hpcrs/README.html#stack-features">Stack features</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../hpcrs/README.html#get-the-pre-built-hpcrs-container-image">Get the pre-built HPCRS container image</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../hpcrs/README.html#build-the-hpcrs-container-image-from-source">Build the HPCRS container image from source</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../hpcrs/README.html#use-the-hpcrs-container-image">Use the HPCRS container image</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../hpcrs/README.html#convert-the-hpcrs-image-to-a-singularity-image">Convert the HPCRS image to a Singularity image</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../hpcrs/README.html#reporting-security-issues">Reporting Security Issues</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../hpcrs/README.html#legal-notice">LEGAL NOTICE</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../hpcrs/NEWS.html">Release notes for HPCRS</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../hpcrs/NEWS.html#release-v0-3-0">Release <code class="docutils literal notranslate"><span class="pre">v0.3.0</span></code> :</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../hpcrs/terms_of_use.html">High Performance Computing Reference Stack Terms of Use</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../hpcrs/index.html#guides">Guides</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../hpcrs/d2s/README.html">Overview</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../hpcrs/d2s/README.html#version-compatibility-verified">Version compatibility verified</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../hpcrs/d2s/README.html#singularity">Singularity</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../hpcrs/d2s/README.html#charliecloud">Charliecloud</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../hpcrs/d2s/README.html#d2s-a-tool-to-convert-docker-images-to-singularity-images-or-charliecloud-directories">d2s - A tool to convert Docker images to Singularity images or Charliecloud directories</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../hpcrs/d2s/README.html#getting-d2s">Getting d2s</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../hpcrs/d2s/README.html#converting-to-a-singularity-image">Converting to a Singularity Image</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../hpcrs/d2s/README.html#converting-to-a-charliecloud-directory">Converting to a Charliecloud directory</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../hpcrs/docs/FAQ.html">HPCRS Frequently Asked Questions (FAQ)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../hpcrs/docs/hpcrs_tutorial.html">HPCRS Tutorial – Creating an Environment for Running Workloads</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../hpcrs/docs/hpcrs_tutorial.html#hardware-configuration">Hardware Configuration</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../hpcrs/docs/hpcrs_tutorial.html#software-prerequisites">Software Prerequisites</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../hpcrs/docs/hpcrs_tutorial.html#software-configuration">Software Configuration</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../hpcrs/docs/hpcrs_tutorial.html#configuring-the-kubernetes-master">Configuring the Kubernetes master</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../hpcrs/docs/hpcrs_tutorial.html#add-and-build-qe">Add and Build QE</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../hpcrs/docs/hpcrs_tutorial.html#run-qe-on-the-hpcrs-image">Run  QE on the HPCRS image</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../hpcrs/docs/hpcrs_tutorial.html#pytorch-benchmarks">PyTorch benchmarks</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../hpcrs/docs/hpcrs_tutorial.html#using-dcp">Using DCP++</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../hpcrs/docs/hpcrs_tutorial.html#using-spack-to-list-available-recipes">Using Spack* to list available recipes</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../hpcrs/docs/hpcrs_tutorial.html#hpcrs-and-the-intel-vtune-profiler">HPCRS and the Intel® VTune™ Profiler</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../oneContainer/index.html">oneContainer Resources</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../oneContainer/index.html#onecontainer-api">oneContainer API</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../oneContainer/index.html#onecontainer-templates">oneContainer Templates</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../oneContainer/index.html#onecontainer-cloud-tool">oneContainer Cloud Tool</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../whitepapers/index.html">System Stacks Whitepapers</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../whitepapers/index.html#identify-galaxies-using-the-deep-learning-reference-stack">Identify Galaxies Using the Deep Learning Reference Stack</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../whitepapers/index.html#github-issue-classification-utilizing-the-end-to-end-system-stacks">GitHub* Issue Classification Utilizing the End-to-End System Stacks</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../whitepapers/index.html#using-ai-to-help-save-lives">Using AI to Help Save Lives</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../whitepapers/index.html#state-of-the-art-bert-fine-tune-training-and-inference-on-3rd-gen-intel-xeon-scalable-processors-with-the-intel-deep-learning-reference-stack">State-of-the-art BERT Fine-tune Training and Inference on 3rd Gen Intel® Xeon® Scalable processors with the Intel Deep Learning Reference Stack</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../whitepapers/index.html#pix2pix-utilizing-the-deep-learning-reference-stack">Pix2Pix: Utilizing the Deep Learning Reference Stack</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../whitepapers/index.html#next-generation-hybrid-cloud-data-analytics-solution">Next-Generation Hybrid Cloud Data Analytics Solution</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../whitepapers/index.html#deploying-machine-learning-models-with-dlrs-and-tensorflow-serving">Deploying Machine Learning Models with DLRS and TensorFlow* Serving</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../whitepapers/index.html#performance-models-in-runway-ml-with-the-deep-learning-reference-stack">Performance Models in Runway ML with the Deep Learning Reference Stack</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../whitepapers/index.html#deep-learning-functions-as-a-service">Deep Learning Functions as a Service</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../perf.html">Performance and Benchmarks</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../perf.html#deep-learning-reference-stack">Deep Learning Reference Stack</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../perf.html#high-performance-computing-reference-stack">High Performance Computing Reference Stack</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../perf.html#data-services-reference-stack">Data Services Reference Stack</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../perf.html#media-reference-stack">Media Reference Stack</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference external" href="https://github.com/intel/stacks-usecase">Real World Use Cases</a></li>
<li class="toctree-l1"><a class="reference external" href="https://github.com/intel/stacks">Project GitHub repository</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../index.html">System Stacks for Linux* OS</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content style-external-links">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../../index.html" class="icon icon-home"></a> &raquo;</li>
      <li>Deep Learning Reference Stack Release Notes</li>

  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="deep-learning-reference-stack-release-notes">
<h1>Deep Learning Reference Stack Release Notes<a class="headerlink" href="#deep-learning-reference-stack-release-notes" title="Permalink to this headline"></a></h1>
<p>The Deep Learning Reference Stack is an integrated, highly-performant open source stack optimized for Intel® Xeon® Scalable platforms. This open source community release is part of our effort to ensure AI developers have easy access to all of the features and functionality of the Intel platforms.  The Deep Learning Reference Stack is highly-tuned and built for cloud native environments. With this stack, we are enabling developers to quickly prototype by reducing the complexity associated with integrating multiple software components, while still giving users the flexibility to customize their solutions. This version includes additional components to provide greater flexibility and a more comprehensive take on the deep learning environment.</p>
<p>To offer more flexibility, we are releasing multiple versions of the Deep Learning Reference Stack. We offer versions built on either Clear Linux OS or Ubuntu* to meet differing needs.</p>
<section id="the-deep-learning-reference-stack-release-built-on-clear-linux-os">
<h2>The Deep Learning Reference Stack Release built on Clear Linux OS<a class="headerlink" href="#the-deep-learning-reference-stack-release-built-on-clear-linux-os" title="Permalink to this headline"></a></h2>
<blockquote>
<div><p><strong>Note:</strong>
The minimum validated version of Clear Linux for this stack is 32690.</p>
</div></blockquote>
<section id="the-deep-learning-reference-stack-with-tensorflow-2-2-onednn-and-intel-avx512-deep-learning-boost-built-on-clear-linux-os">
<h3>The Deep Learning Reference Stack with Tensorflow 2.2, oneDNN and Intel® AVX512-Deep Learning Boost built on Clear Linux OS<a class="headerlink" href="#the-deep-learning-reference-stack-with-tensorflow-2-2-onednn-and-intel-avx512-deep-learning-boost-built-on-clear-linux-os" title="Permalink to this headline"></a></h3>
<p>The <a class="reference external" href="https://hub.docker.com/r/sysstacks/dlrs-tensorflow2-clearlinux/">dlrs-tensorflow2-clearlinux</a> version v0.6.0 includes:</p>
<ul class="simple">
<li><p>Clear Linux* OS version 32690</p></li>
<li><p>Runtimes (Python 3)</p></li>
<li><p>TensorFlow 2.2.0-rc0 optimized using oneAPI Deep Neural Network Library (oneDNN) primitives and Intel® AVX-512 Deep Learning Boost (Formerly Intel® VNNI)</p></li>
<li><p>Intel OpenVINO™ model server v2020.1</p></li>
<li><p>Transformers - State-of-the-art Natural Language Processing for TensorFlow 2.2.0-rc0</p></li>
<li><p>Jupyterhub 1.1.0</p></li>
<li><p>Seldon-core 1.0.1</p></li>
</ul>
</section>
<section id="the-deep-learning-reference-stack-with-tensorflow-1-15-onednn-and-intel-avx512-deep-learning-boost-built-on-clear-linux-os">
<h3>The Deep Learning Reference Stack with Tensorflow 1.15, oneDNN and Intel® AVX512-Deep Learning Boost built on Clear Linux OS<a class="headerlink" href="#the-deep-learning-reference-stack-with-tensorflow-1-15-onednn-and-intel-avx512-deep-learning-boost-built-on-clear-linux-os" title="Permalink to this headline"></a></h3>
<p>The <a class="reference external" href="https://hub.docker.com/r/sysstacks/dlrs-tensorflow-clearlinux/">dlrs-tensorflow-clearlinux</a> version v0.6.0 includes:</p>
<ul class="simple">
<li><p>Clear Linux* OS version 32690</p></li>
<li><p>Runtimes (Python 3)</p></li>
<li><p>TensorFlow 1.15 optimized using oneAPI Deep Neural Network Library (oneDNN) primitives and Intel® AVX-512 Deep Learning Boost (Formerly Intel® VNNI)</p></li>
<li><p>Intel OpenVINO™ model server v2020.1</p></li>
<li><p>Jupyterhub 1.1.0</p></li>
<li><p>Seldon-core 1.0.1</p></li>
</ul>
</section>
<section id="the-deep-learning-reference-stack-with-eigen-built-on-clear-linux-os">
<h3>The Deep Learning Reference Stack with Eigen built on Clear Linux OS<a class="headerlink" href="#the-deep-learning-reference-stack-with-eigen-built-on-clear-linux-os" title="Permalink to this headline"></a></h3>
<p>The <a class="reference external" href="https://hub.docker.com/r/sysstacks/dlrs-tensorflow-clearlinux/">dlrs-tensorflow-clearlinux:v0.6.0-oss</a> version v0.6.0 includes:</p>
<ul class="simple">
<li><p>Clear Linux* OS version 32690</p></li>
<li><p>TensorFlow 2.0 compiled with AVX2 and AVX512 optimizations</p></li>
<li><p>Runtimes (Python 3)</p></li>
<li><p>Jupyter-notebook 6.0.3</p></li>
<li><p>Seldon-core 1.0.1</p></li>
</ul>
</section>
<section id="the-deep-learning-reference-stack-with-pytorch-and-intel-mkl-built-on-clear-linux-os">
<h3>The Deep Learning Reference Stack with PyTorch and Intel® MKL built on Clear Linux OS<a class="headerlink" href="#the-deep-learning-reference-stack-with-pytorch-and-intel-mkl-built-on-clear-linux-os" title="Permalink to this headline"></a></h3>
<p>The <a class="reference external" href="https://hub.docker.com/r/sysstacks/dlrs-pytorch-clearlinux/">dlrs-pytorch-clearlinux</a> version v0.6.0 includes:</p>
<ul class="simple">
<li><p>Clear Linux* OS version 32690</p></li>
<li><p>Runtimes (Python 3)</p></li>
<li><p>PyTorch version 1.4.0 optimized using Intel® Math Kernel Library, oneAPI Deep Neural Network Library (oneDNN) primitives and Intel® AVX-512 Deep Learning Boost (Formerly Intel® VNNI)</p></li>
<li><p>PyTorch lightning version v0.6.0</p></li>
<li><p>Transformers - State-of-the-art Natural Language Processing for PyTorch 1.14</p></li>
<li><p>Flair for Natural Language Processing version v0.4.5</p></li>
<li><p>Jupyterhub 1.1.0</p></li>
<li><p>Seldon-core 1.0.1</p></li>
</ul>
</section>
<section id="the-deep-learning-reference-stack-with-pytorch-built-on-clear-linux-os">
<h3>The Deep Learning Reference Stack with PyTorch built on Clear Linux OS<a class="headerlink" href="#the-deep-learning-reference-stack-with-pytorch-built-on-clear-linux-os" title="Permalink to this headline"></a></h3>
<p>The <a class="reference external" href="https://hub.docker.com/r/sysstacks/dlrs-pytorch-clearlinux/">dlrs-pytorch-clearlinux:v0.6.0-oss</a> version v0.6.0 includes:</p>
<ul class="simple">
<li><p>Clear Linux* OS version 32690</p></li>
<li><p>Runtimes (Python 3)</p></li>
<li><p>PyTorch version 1.4.0 with OpenBLAS version 0.3.9</p></li>
<li><p>Jupyter-notebook 6.0.3</p></li>
<li><p>Seldon-core 1.0.1</p></li>
</ul>
</section>
<section id="deep-learning-compilers-built-on-clear-linux-os">
<h3>Deep Learning Compilers built on Clear Linux OS<a class="headerlink" href="#deep-learning-compilers-built-on-clear-linux-os" title="Permalink to this headline"></a></h3>
<p>The <a class="reference external" href="https://hub.docker.com/r/sysstacks/dlrs-ml-compiler-clearlinux/">dlrs-ml-compiler-clearlinux</a> version v0.6.0 includes:</p>
<ul class="simple">
<li><p>Clear Linux* OS version 32690</p></li>
<li><p>TVM version 0.6 optimized using the Intel® Math Kernel Library</p></li>
<li><p>Jupyter-notebook 6.0.3</p></li>
</ul>
</section>
</section>
<section id="the-deep-learning-reference-stack-release-built-on-ubuntu">
<h2>The Deep Learning Reference Stack Release built on Ubuntu<a class="headerlink" href="#the-deep-learning-reference-stack-release-built-on-ubuntu" title="Permalink to this headline"></a></h2>
<section id="the-deep-learning-reference-stack-tensorflow-2-2-0-with-onednn-primitives-intel-mkl-intel-dlboost-and-openvino-deep-learning-deployment-toolkit-v2020-1-tbb-built-on-ubuntu">
<h3>The Deep Learning Reference Stack TensorFlow 2.2.0 with oneDNN primitives, Intel® MKL, Intel® DLBoost and OpenVINO™ - Deep Learning Deployment Toolkit v2020.1 (TBB) built on Ubuntu<a class="headerlink" href="#the-deep-learning-reference-stack-tensorflow-2-2-0-with-onednn-primitives-intel-mkl-intel-dlboost-and-openvino-deep-learning-deployment-toolkit-v2020-1-tbb-built-on-ubuntu" title="Permalink to this headline"></a></h3>
<p>The <a class="reference external" href="https://hub.docker.com/r/sysstacks/dlrs-tensorflow2-ubuntu">dlrs-tensorflow2-ubuntu</a> version v0.6.1 includes:</p>
<ul class="simple">
<li><p>Ubuntu 20.04</p></li>
<li><p>Runtimes (Python 3)</p></li>
<li><p>TensorFlow 2.2.0 optimized using oneAPI Deep Neural Network Library (oneDNN) primitives and Intel® AVX-512 Deep Learning Boost (Formerly Intel® VNNI)</p></li>
<li><p>Intel OpenVINO™ model server v2020.1</p></li>
<li><p>Transformers - State-of-the-art Natural Language Processing for TensorFlow 2.2.0</p></li>
<li><p>Jupyterhub 1.1.0</p></li>
<li><p>Seldon-core 1.0.1</p></li>
</ul>
</section>
<section id="the-deep-learning-reference-stack-with-tensorflow-1-15-2-intel-mkl-dnn-and-intel-avx512-deep-learning-boost-v0-6-1-built-on-ubuntu">
<h3>The Deep Learning Reference Stack with Tensorflow 1.15.2, Intel® MKL-DNN and Intel® AVX512-Deep Learning Boost (v0.6.1) built on Ubuntu<a class="headerlink" href="#the-deep-learning-reference-stack-with-tensorflow-1-15-2-intel-mkl-dnn-and-intel-avx512-deep-learning-boost-v0-6-1-built-on-ubuntu" title="Permalink to this headline"></a></h3>
<p>The <a class="reference external" href="https://hub.docker.com/r/sysstacks/dlrs-tensorflow-ubuntu">dlrs-tensorflow-ubuntu</a> version v0.6.1 includes:</p>
<ul class="simple">
<li><p>Ubuntu 20.04</p></li>
<li><p>Runtimes (Python 3)</p></li>
<li><p>TensorFlow 1.15.2 optimized using oneAPI Deep Neural Network Library (oneDNN) primitives and Intel® AVX-512 Deep Learning Boost (Formerly Intel® VNNI)</p></li>
<li><p>Intel OpenVINO™ model server v2020.1</p></li>
<li><p>Jupyterhub 1.1.0</p></li>
<li><p>Seldon-core 1.0.1</p></li>
</ul>
</section>
<section id="id1">
<h3>The Deep Learning Reference Stack with PyTorch built on Clear Linux OS<a class="headerlink" href="#id1" title="Permalink to this headline"></a></h3>
<p>The <a class="reference external" href="https://hub.docker.com/r/sysstacks/dlrs-pytorch-ubuntu/">dlrs-pytorch-ubuntu</a> version v0.6.1 includes:</p>
<ul class="simple">
<li><p>Ubuntu 20.04</p></li>
<li><p>Runtimes (Python 3)</p></li>
<li><p>PyTorch version 1.4.0</p></li>
<li><p>Jupyterhub 1.1.0</p></li>
<li><p>Seldon-core 1.0.1</p></li>
</ul>
</section>
<section id="how-to-get-the-deep-learning-reference-stack">
<h3>How to get the Deep Learning Reference Stack<a class="headerlink" href="#how-to-get-the-deep-learning-reference-stack" title="Permalink to this headline"></a></h3>
<p>The official Deep Learning Reference Stack Docker images are hosted at: https://hub.docker.com/r/sysstacks/.</p>
<blockquote>
<div><p><strong>Note:</strong>
The System Stacks team is transitioning into a new organization in Github and Dockerhub, please note all images are now under the <code class="docutils literal notranslate"><span class="pre">sysstacks</span></code> namespace.</p>
</div></blockquote>
<section id="clear-linux-os-versions">
<h4>Clear Linux OS versions<a class="headerlink" href="#clear-linux-os-versions" title="Permalink to this headline"></a></h4>
<ul class="simple">
<li><p>Pull from the <a class="reference external" href="https://hub.docker.com/r/sysstacks/dlrs-tensorflow-clearlinux">Tensorflow 1.15 and oneDNN version</a></p></li>
<li><p>Pull from the <a class="reference external" href="https://hub.docker.com/r/sysstacks/dlrs-tensorflow2-clearlinux">Tensorflow 2.2.0-rc0 and oneDNN version</a></p></li>
<li><p>Pull from the <a class="reference external" href="https://hub.docker.com/r/sysstacks/dlrs-tensorflow-clearlinux">Tensorflow with Eigen version</a></p></li>
<li><p>Pull from the <a class="reference external" href="https://hub.docker.com/r/sysstacks/dlrs-pytorch-clearlinux">PyTorch with oneDNN and Intel® MKL version</a></p></li>
<li><p>Pull from the <a class="reference external" href="https://hub.docker.com/r/sysstacks/dlrs-pytorch-clearlinux">PyTorch with OpenBLAS version</a></p></li>
<li><p>Pull from the <a class="reference external" href="https://hub.docker.com/r/sysstacks/dlrs-ml-compiler-clearlinux">ML Compiler with Intel® MKL version</a></p></li>
</ul>
</section>
<section id="ubuntu-versions">
<h4>Ubuntu versions<a class="headerlink" href="#ubuntu-versions" title="Permalink to this headline"></a></h4>
<ul class="simple">
<li><p>Pull from the <a class="reference external" href="https://hub.docker.com/r/sysstacks/dlrs-tensorflow2-ubuntu">TensorFlow 2.2.0 with oneDNN primitives version</a></p></li>
<li><p>Pull from the <a class="reference external" href="https://hub.docker.com/r/sysstacks/dlrs-tensorflow-ubuntu">Tensorflow 1.15, Intel® MKL-DNN and Intel® AVX512-Deep Learning Boost version</a></p></li>
<li><p>Pull from the <a class="reference external" href="https://hub.docker.com/r/sysstacks/dlrs-pytorch-ubuntu">PyTorch and Intel® MKL version</a></p></li>
</ul>
<blockquote>
<div><p><strong>Note:</strong>
To take advantage of the AVX-512, and AVX-512 Deep Learning Boost functionality with the Deep Learning Reference Stack, please use the following hardware:
* AVX 512 images require an Intel® Xeon® Scalable Platform
* AVX-512 Deep Learning Boost requires a Second-Generation Intel® Xeon® Scalable Platform</p>
</div></blockquote>
</section>
</section>
</section>
<section id="licensing">
<h2>Licensing<a class="headerlink" href="#licensing" title="Permalink to this headline"></a></h2>
<p>The Deep Learning Reference Stack is guided by these <a class="reference external" href="https://clearlinux.org/stacks/deep-learning/terms-of-use">Terms of Use</a>. The Docker images are hosted on https://hub.docker.com and as with all Docker images, these likely also contain other software which may be under other licenses (such as Bash, etc. from the base distribution, along with any direct or indirect dependencies of the primary software being contained).</p>
</section>
<section id="working-with-the-deep-learning-reference-stack">
<h2>Working with the Deep Learning Reference Stack<a class="headerlink" href="#working-with-the-deep-learning-reference-stack" title="Permalink to this headline"></a></h2>
<p>The Deep Learning Reference Stack includes TensorFlow and Kubeflow support.
These software components were selected because they are most popular/widely used by developers and CSPs. Clear Linux provides optimizations across the entire OS stack for the ultimate end user performance and is customizable to meet your unique needs. TensorFlow was selected as it is the leading deep learning and machine learning framework. oneAPI Deep Neural Network Library (oneDNN) is an open source performance library for Deep Learning (DL) applications intended for acceleration of DL frameworks on Intel® architecture. Intel® oneDNN includes highly vectorized and threaded building blocks to implement convolutional neural networks (CNN) with C and C++ interfaces.  Kubeflow  is a project that provides a straightforward way to deploy simple, scalable and portable Machine Learning workflows on Kubernetes. This combination of an operating system and the deep learning framework and libraries results in a performant deep learning software stack.</p>
<p>Please refer to the <a class="reference external" href="https://docs.01.org/clearlinux/latest/guides/stacks/dlrs.html">Deep Learning Reference Stack guide</a> for detailed instructions for running the TensorFlow and Kubeflow Benchmarks on the docker images.</p>
<blockquote>
<div><p><strong>Note:</strong>
Although the DLRS images and dockerfiles may be modified for your needs, there are some modifications that may cause unexpected or undesirable results. For example, using the Clear Linux <code class="docutils literal notranslate"><span class="pre">swupd</span> <span class="pre">bundle-add</span></code> command to add packages to a Clear Linux based container may overwrite the DLRS core components. Please use care when modifying the contents of the containers. A listing of the core components can be found in the <a class="reference external" href="https://github.com/intel/stacks/blob/master/dlrs/clearlinux/releasenote.md">release notes</a> for each release.</p>
</div></blockquote>
</section>
<section id="performance-tuning-configurations">
<h2>Performance tuning configurations<a class="headerlink" href="#performance-tuning-configurations" title="Permalink to this headline"></a></h2>
<section id="single-node-configuration">
<h3>Single Node Configuration<a class="headerlink" href="#single-node-configuration" title="Permalink to this headline"></a></h3>
<table border="1" class="docutils">
<thead>
<tr>
<th>Key</th>
<th>Value</th>
</tr>
</thead>
<tbody>
<tr>
<td>num_inter_threads</td>
<td>Socket number</td>
</tr>
<tr>
<td>num_intra_threads</td>
<td>Physical cores number</td>
</tr>
<tr>
<td>data_format</td>
<td>NHWC for Eigen; NCHW for MKL as MKL is optimized for this format</td>
</tr>
</tbody>
</table><p>Example: For Intel® Xeon® Gold 6140 CPU &#64; 2.30GHz with 2 Sockets and 18 Cores/Socket MKL training with batch size 32:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>  <span class="n">python</span> <span class="n">tf_cnn_benchmarks</span><span class="o">.</span><span class="n">py</span> <span class="o">--</span><span class="n">device</span><span class="o">=</span><span class="n">cpu</span> <span class="o">--</span><span class="n">mkl</span><span class="o">=</span><span class="kc">True</span> <span class="o">--</span><span class="n">nodistortions</span> <span class="o">--</span><span class="n">model</span><span class="o">=</span><span class="n">resnet50</span> <span class="o">--</span><span class="n">data_format</span><span class="o">=</span><span class="n">NCHW</span> <span class="o">--</span><span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span> <span class="o">--</span><span class="n">num_inter_threads</span><span class="o">=</span><span class="mi">2</span> <span class="o">--</span><span class="n">num_intra_threads</span><span class="o">=</span><span class="mi">36</span> <span class="o">--</span><span class="n">data_dir</span><span class="o">=/</span><span class="n">imagenet</span><span class="o">-</span><span class="n">TFrecord</span> <span class="o">--</span><span class="n">data_name</span><span class="o">=</span><span class="n">imagenet</span>
</pre></div>
</div>
</section>
<section id="multi-node-configuration">
<h3>Multi-node Configuration<a class="headerlink" href="#multi-node-configuration" title="Permalink to this headline"></a></h3>
<p>The Deep Learning Reference Stack can be used in a multi node configuration using Kubernetes and different machine learning frameworks and libraries. Please refer to the System Stacks <a class="reference external" href="https://github.com/intel/stacks-usecase">usecases repo</a> to find examples on how to setup the Deep Learning Reference Stack with Kubeflow for multi-node.</p>
<p>For multi-node training please refer to:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://docs.01.org/clearlinux/latest/guides/stacks/dlrs.html#id12">PyTorch multi-node using Kubeflow</a></p></li>
<li><p><a class="reference external" href="https://docs.01.org/clearlinux/latest/guides/stacks/dlrs.html#id11">Tensorflow multi-node using Kubeflow</a></p></li>
</ul>
</section>
</section>
<section id="contributing-to-the-deep-learning-reference-stack">
<h2>Contributing to the Deep Learning Reference Stack<a class="headerlink" href="#contributing-to-the-deep-learning-reference-stack" title="Permalink to this headline"></a></h2>
<p>We encourage your contributions to this project, through the established Clear Linux community tools.  Our team uses typical open source collaboration tools that are described on the Clear Linux <a class="reference external" href="https://clearlinux.org/community">community page</a>.</p>
</section>
<section id="reporting-security-issues">
<h2>Reporting Security Issues<a class="headerlink" href="#reporting-security-issues" title="Permalink to this headline"></a></h2>
<p>If you have discovered potential security vulnerability in an Intel product, please contact the iPSIRT at secure&#64;intel.com.</p>
<p>It is important to include the following details:</p>
<ul class="simple">
<li><p>The products and versions affected</p></li>
<li><p>Detailed description of the vulnerability</p></li>
<li><p>Information on known exploits</p></li>
</ul>
<p>Vulnerability information is extremely sensitive. The iPSIRT strongly recommends that all security vulnerability reports sent to Intel be encrypted using the iPSIRT PGP key. The PGP key is available here: https://www.intel.com/content/www/us/en/security-center/pgp-public-key.html</p>
<p>Software to encrypt messages may be obtained from:</p>
<ul class="simple">
<li><p>PGP Corporation</p></li>
<li><p>GnuPG</p></li>
</ul>
</section>
</section>


           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2020.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>