<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Deep Learning Reference Stack with TensorFlow and Intel® oneAPI Deep Neural Network Library (oneDNN) &mdash; System Stacks for Linux* OS  documentation</title>
      <link rel="stylesheet" href="../../../../../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../../../../../_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="../../../../../_static/tabs.css" type="text/css" />
      <link rel="stylesheet" href="../../../../../_static/css/custom.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../../../../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../../../../../" id="documentation_options" src="../../../../../_static/documentation_options.js"></script>
        <script src="../../../../../_static/jquery.js"></script>
        <script src="../../../../../_static/underscore.js"></script>
        <script src="../../../../../_static/doctools.js"></script>
    <script src="../../../../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../../search.html" />
    <link href="../../../../../_static/css/custom.css" rel="stylesheet" type="text/css">

</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../../../../../index.html" class="icon icon-home"> System Stacks for Linux* OS
            <img src="../../../../../_static/stacks_logo.png" class="logo" alt="Logo"/>
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../../README.html">Stacks containers have been deprecated and please switch to oneapi based containers, you can find oneapi containers at this link :  https://hub.docker.com/u/intel</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../../../README.html#system-stacks-for-linux-os">System Stacks for Linux* OS</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../../README.html#contributing">Contributing</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../README.html#security-issues">Security Issues</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../README.html#mailing-list">Mailing List</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../../index.html">Deep Learning Reference Stack</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../../index.html#dlrs-release-announcement-and-performance-reports">DLRS Release Announcement and Performance Reports</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../index.html#dlrs-guides">DLRS Guides</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../dlrs.html">Deep Learning Reference Stack Guide</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../../dlrs.html#overview">Overview</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../dlrs.html#releases">Releases</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../dlrs.html#tensorflow-single-and-multi-node-benchmarks">TensorFlow single and multi-node benchmarks</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../dlrs.html#pytorch-single-and-multi-node-benchmarks">PyTorch single and multi-node benchmarks</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../dlrs.html#tensorflow-training-tfjob-with-kubeflow-and-dlrs">TensorFlow Training (TFJob) with Kubeflow and DLRS</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../dlrs.html#pytorch-training-pytorch-job-with-kubeflow-and-dlrs">PyTorch Training (PyTorch Job) with Kubeflow and DLRS</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../dlrs.html#working-with-horovod-and-openmpi">Working with Horovod* and OpenMPI*</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../dlrs.html#using-transformers-for-natural-language-processing">Using Transformers* for Natural Language Processing</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../dlrs.html#using-the-openvino-model-optimizer">Using the OpenVINO™ Model Optimizer</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../dlrs.html#using-the-openvino-toolkit-inference-engine">Using the OpenVINO™ toolkit Inference Engine</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../dlrs.html#using-seldon-and-openvino-model-server-with-the-deep-learning-reference-stack">Using Seldon and OpenVINO™ model server with the Deep Learning Reference Stack</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../dlrs.html#use-jupyter-notebook">Use Jupyter Notebook</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../dlrs.html#uninstallation">Uninstallation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../dlrs.html#compiling-aixprt-with-openmp-on-dlrs">Compiling AIXPRT with OpenMP on DLRS</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../dlrs.html#using-the-intel-vtune-profiler-with-dlrs-containers">Using the Intel® VTune™ Profiler with DLRS Containers</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../dlrs.html#related-resources">Related Resources</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../../bert-performance.html">State-of-the-art BERT Fine-tune training and Inference</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../../bert-performance.html#overview">Overview</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../bert-performance.html#recommended-hardware">Recommended Hardware</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../bert-performance.html#required-software">Required Software</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../bert-performance.html#steps">Steps</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../bert-performance.html#run-bert-fine-tune-training-with-the-squad-1-1-data-set">Run BERT Fine-tune training with the Squad 1.1 data set</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../bert-performance.html#notices-and-disclaimers">NOTICES AND DISCLAIMERS</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../index.html#dlrs-releases">DLRS Releases</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../index.html#dlrs-with-tensorflow">DLRS with TensorFlow*</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../../tensorflow/README.html">Deep Learning Reference Stack with Tensorflow and Intel® oneAPI Deep Neural Network Library (oneDNN)</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../../index.html#dlrs-with-tensorflow-serving">DLRS with TensorFlow Serving*</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../../serving/README.html">Build instructions</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../../index.html#dlrs-with-pytorch">DLRS with PyTorch*</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../../pytorch/README.html">Deep Learning Reference Stack with Pytorch and Intel® oneAPI Deep Neural Network Library (oneDNN)</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../../index.html#dlrs-ml-compiler">DLRS ML Compiler</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../../ml-compiler/README.html">Stacks Deep Learning Compiler</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../dsrs/index.html">Data Services Reference Stack</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../../../dsrs/index.html#overview">Overview</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../../dsrs/README.html">Data Services Reference Stack (DSRS) Overview</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../dsrs/terms_of_use.html">Data Services Reference Stack Terms of Use</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../dsrs/index.html#memcached-versions">memcached* versions</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../../../dsrs/memcached/README.html">Data Services Reference Stack(DSRS) - Memcached*</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../dsrs/index.html#redis-versions">Redis* versions</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../../../dsrs/redis/README.html">Data Services Reference Stack(DSRS) - Redis*</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../mers/index.html">Media Reference Stack</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../../../mers/index.html#overview">Overview</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../../mers/README.html">Media Reference Stack</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../../../mers/README.html#mers-on-intel-onecontainer-portal">MeRS on Intel® oneContainer Portal</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../mers/README.html#source-code">Source Code</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../mers/README.html#reporting-security-issues">Reporting Security Issues</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../mers/README.html#supported-platforms-and-media-codecs">Supported Platforms and Media Codecs</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../mers/releasenotes.html">Media Reference Stack Release Notes</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../../../mers/releasenotes.html#the-media-reference-stack">The Media Reference Stack</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../mers/releasenotes.html#licensing">Licensing</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../mers/releasenotes.html#the-media-reference-stack-licenses">The Media Reference Stack licenses</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../mers/releasenotes.html#disclaimer">Disclaimer</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../mers/releasenotes.html#source-code">Source code</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../mers/releasenotes.html#contributing-to-the-media-reference-stack">Contributing to the Media Reference Stack</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../mers/releasenotes.html#reporting-security-issues">Reporting Security Issues</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../mers/terms_of_use.html">Media Reference Stack Terms of Use</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../mers/CONTRIBUTING.html">Contributing</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../../../mers/CONTRIBUTING.html#pull-request-process">Pull Request Process</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../mers/CONTRIBUTING.html#code-of-conduct">Code of Conduct</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../mers/AUTHORS.html">Media Reference Stack Authors</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../mers/LICENSES.html">Licenses</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../../../mers/LICENSES.html#mers-licenses">MeRS licenses</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../mers/LICENSES.html#disclaimer">Disclaimer</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../../mers/index.html#guide">Guide</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../../mers/mers.html">Media Reference Stack Guide</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../../../mers/mers.html#overview">Overview</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../mers/mers.html#releases">Releases</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../mers/mers.html#get-the-pre-built-mers-container-image">Get the pre-built MeRS container image</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../mers/mers.html#build-the-mers-container-image-from-source">Build the MeRS container image from source</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../mers/mers.html#use-the-mers-container-image">Use the MeRS container image</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../mers/mers.html#add-aom-support">Add AOM support</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../../mers/index.html#ubuntu-releases">Ubuntu* Releases</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../../mers/ubuntu/INSTALL.html">Media Reference Stack - Ubuntu*</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../../../mers/ubuntu/INSTALL.html#building-container-image">Building container image</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../mers/ubuntu/INSTALL.html#getting-mers-pre-built-image">Getting MeRS pre-built image</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../mers/ubuntu/INSTALL.html#running-the-media-container">Running the Media Container</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../mers/ubuntu/INSTALL.html#run-examples">Run examples</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../mers/ubuntu/INSTALL.html#reporting-security-issues">Reporting Security Issues</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../mers/ubuntu/INSTALL.html#legal-notice">LEGAL NOTICE</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../mers/NEWS.html">Changes for <code class="docutils literal notranslate"><span class="pre">v0.4.0</span></code> :</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../mers/NEWS.html#changes-for-v0-3-0">Changes for <code class="docutils literal notranslate"><span class="pre">v0.3.0</span></code> :</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../mers/NEWS.html#changes-for-v0-2-0">Changes for <code class="docutils literal notranslate"><span class="pre">v0.2.0</span></code> :</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../mers/NEWS.html#changes-for-v0-1-0">Changes for <code class="docutils literal notranslate"><span class="pre">v0.1.0</span></code> :</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../mers/BUGS.html">Known Issues</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../../../mers/BUGS.html#mers-v0-4-0">MeRS <code class="docutils literal notranslate"><span class="pre">v0.4.0</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../mers/BUGS.html#mers-v0-3-0">MeRS <code class="docutils literal notranslate"><span class="pre">v0.3.0</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../mers/BUGS.html#mers-v0-2-0">MeRS <code class="docutils literal notranslate"><span class="pre">v0.2.0</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../mers/BUGS.html#mers-v0-1-0">MeRS <code class="docutils literal notranslate"><span class="pre">v0.1.0</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../mers/CHANGELOG.html">0.4.0 (2021-04-19)</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../../../mers/CHANGELOG.html#functionality-changes">Functionality Changes</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../mers/CHANGELOG.html#deprecated-features">Deprecated Features</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../mers/CHANGELOG.html#new-features">New Features</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../mers/CHANGELOG.html#refactors">Refactors</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../mers/CHANGELOG.html#changelog-v0-3-0-2020-11-18">Changelog v0.3.0 (2020-11-18)</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../../../mers/CHANGELOG.html#id2">Functionality Changes</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../mers/CHANGELOG.html#chores">Chores</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../mers/CHANGELOG.html#documentation-changes">Documentation Changes</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../mers/CHANGELOG.html#id3">New Features</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../mers/CHANGELOG.html#bug-fixes">Bug Fixes</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../mers/CHANGELOG.html#id4">Refactors</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../mers/CHANGELOG.html#removed-features">Removed Features</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../mers/CHANGELOG.html#security">Security</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../mers/CHANGELOG.html#id5">0.2.0 (2020-04-14)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../mers/CHANGELOG.html#id6">0.1.0 (2019-10-31)</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../../mers/index.html#deprecated-releases">Deprecated Releases</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../../mers/deprecated/clearlinux/INSTALL.html">Media Reference Stack - Clear Linux* OS</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../../../mers/deprecated/clearlinux/INSTALL.html#building-locally">Building Locally</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../mers/deprecated/clearlinux/INSTALL.html#pulling-from-docker-hub">Pulling from Docker Hub</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../mers/deprecated/clearlinux/INSTALL.html#running-the-media-container">Running the Media Container</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../mers/deprecated/clearlinux/INSTALL.html#run-examples">Run examples</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../hpcrs/index.html">High Performance Computing Reference Stack</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../../../hpcrs/index.html#overview">Overview</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../../hpcrs/README.html">High Performance Compute Reference Stack</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../../../hpcrs/README.html#overview">Overview</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../hpcrs/README.html#releases">Releases</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../hpcrs/README.html#stack-features">Stack features</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../hpcrs/README.html#get-the-pre-built-hpcrs-container-image">Get the pre-built HPCRS container image</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../hpcrs/README.html#build-the-hpcrs-container-image-from-source">Build the HPCRS container image from source</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../hpcrs/README.html#use-the-hpcrs-container-image">Use the HPCRS container image</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../hpcrs/README.html#convert-the-hpcrs-image-to-a-singularity-image">Convert the HPCRS image to a Singularity image</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../hpcrs/README.html#reporting-security-issues">Reporting Security Issues</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../hpcrs/README.html#legal-notice">LEGAL NOTICE</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../hpcrs/NEWS.html">Release notes for HPCRS</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../../../hpcrs/NEWS.html#release-v0-3-0">Release <code class="docutils literal notranslate"><span class="pre">v0.3.0</span></code> :</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../hpcrs/terms_of_use.html">High Performance Computing Reference Stack Terms of Use</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../../hpcrs/index.html#guides">Guides</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../../hpcrs/d2s/README.html">Overview</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../../../hpcrs/d2s/README.html#version-compatibility-verified">Version compatibility verified</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../hpcrs/d2s/README.html#singularity">Singularity</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../hpcrs/d2s/README.html#charliecloud">Charliecloud</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../hpcrs/d2s/README.html#d2s-a-tool-to-convert-docker-images-to-singularity-images-or-charliecloud-directories">d2s - A tool to convert Docker images to Singularity images or Charliecloud directories</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../../../hpcrs/d2s/README.html#getting-d2s">Getting d2s</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../hpcrs/d2s/README.html#converting-to-a-singularity-image">Converting to a Singularity Image</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../hpcrs/d2s/README.html#converting-to-a-charliecloud-directory">Converting to a Charliecloud directory</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../hpcrs/docs/FAQ.html">HPCRS Frequently Asked Questions (FAQ)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../../hpcrs/docs/hpcrs_tutorial.html">HPCRS Tutorial – Creating an Environment for Running Workloads</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../../../hpcrs/docs/hpcrs_tutorial.html#hardware-configuration">Hardware Configuration</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../hpcrs/docs/hpcrs_tutorial.html#software-prerequisites">Software Prerequisites</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../hpcrs/docs/hpcrs_tutorial.html#software-configuration">Software Configuration</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../hpcrs/docs/hpcrs_tutorial.html#configuring-the-kubernetes-master">Configuring the Kubernetes master</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../hpcrs/docs/hpcrs_tutorial.html#add-and-build-qe">Add and Build QE</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../hpcrs/docs/hpcrs_tutorial.html#run-qe-on-the-hpcrs-image">Run  QE on the HPCRS image</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../hpcrs/docs/hpcrs_tutorial.html#pytorch-benchmarks">PyTorch benchmarks</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../hpcrs/docs/hpcrs_tutorial.html#using-dcp">Using DCP++</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../hpcrs/docs/hpcrs_tutorial.html#using-spack-to-list-available-recipes">Using Spack* to list available recipes</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../../hpcrs/docs/hpcrs_tutorial.html#hpcrs-and-the-intel-vtune-profiler">HPCRS and the Intel® VTune™ Profiler</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../oneContainer/index.html">oneContainer Resources</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../../../oneContainer/index.html#onecontainer-api">oneContainer API</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../../oneContainer/index.html#onecontainer-templates">oneContainer Templates</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../../oneContainer/index.html#onecontainer-cloud-tool">oneContainer Cloud Tool</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../whitepapers/index.html">System Stacks Whitepapers</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../../../whitepapers/index.html#identify-galaxies-using-the-deep-learning-reference-stack">Identify Galaxies Using the Deep Learning Reference Stack</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../../whitepapers/index.html#github-issue-classification-utilizing-the-end-to-end-system-stacks">GitHub* Issue Classification Utilizing the End-to-End System Stacks</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../../whitepapers/index.html#using-ai-to-help-save-lives">Using AI to Help Save Lives</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../../whitepapers/index.html#state-of-the-art-bert-fine-tune-training-and-inference-on-3rd-gen-intel-xeon-scalable-processors-with-the-intel-deep-learning-reference-stack">State-of-the-art BERT Fine-tune Training and Inference on 3rd Gen Intel® Xeon® Scalable processors with the Intel Deep Learning Reference Stack</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../../whitepapers/index.html#pix2pix-utilizing-the-deep-learning-reference-stack">Pix2Pix: Utilizing the Deep Learning Reference Stack</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../../whitepapers/index.html#next-generation-hybrid-cloud-data-analytics-solution">Next-Generation Hybrid Cloud Data Analytics Solution</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../../whitepapers/index.html#deploying-machine-learning-models-with-dlrs-and-tensorflow-serving">Deploying Machine Learning Models with DLRS and TensorFlow* Serving</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../../whitepapers/index.html#performance-models-in-runway-ml-with-the-deep-learning-reference-stack">Performance Models in Runway ML with the Deep Learning Reference Stack</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../../whitepapers/index.html#deep-learning-functions-as-a-service">Deep Learning Functions as a Service</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../perf.html">Performance and Benchmarks</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../../../perf.html#deep-learning-reference-stack">Deep Learning Reference Stack</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../../perf.html#high-performance-computing-reference-stack">High Performance Computing Reference Stack</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../../perf.html#data-services-reference-stack">Data Services Reference Stack</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../../perf.html#media-reference-stack">Media Reference Stack</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference external" href="https://github.com/intel/stacks-usecase">Real World Use Cases</a></li>
<li class="toctree-l1"><a class="reference external" href="https://github.com/intel/stacks">Project GitHub repository</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../../../index.html">System Stacks for Linux* OS</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content style-external-links">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../../../../index.html" class="icon icon-home"></a> &raquo;</li>
      <li>Deep Learning Reference Stack with TensorFlow and Intel® oneAPI Deep Neural Network Library (oneDNN)</li>

  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="deep-learning-reference-stack-with-tensorflow-and-intel-oneapi-deep-neural-network-library-onednn">
<h1>Deep Learning Reference Stack with TensorFlow and Intel® oneAPI Deep Neural Network Library (oneDNN)<a class="headerlink" href="#deep-learning-reference-stack-with-tensorflow-and-intel-oneapi-deep-neural-network-library-onednn" title="Permalink to this headline"></a></h1>
<p><a class="reference external" href="https://microbadger.com/images/sysstacks/dlrs-tensorflow-clearlinux:v0.6.0"><img alt="https://images.microbadger.com/badges/image/sysstacks/dlrs-tensorflow-clearlinux:v0.6.0.svg" src="https://images.microbadger.com/badges/image/sysstacks/dlrs-tensorflow-clearlinux:v0.6.0.svg" /></a></p>
<section id="building-locally">
<h2>Building Locally<a class="headerlink" href="#building-locally" title="Permalink to this headline"></a></h2>
<p>Default build args in Docker are on: https://docs.docker.com/engine/reference/builder/#arg</p>
<blockquote>
<div><p>NOTE: This command is for locally building this image alone.</p>
</div></blockquote>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">docker</span> <span class="n">build</span> <span class="o">--</span><span class="n">no</span><span class="o">-</span><span class="n">cache</span> <span class="o">--</span><span class="n">build</span><span class="o">-</span><span class="n">arg</span> <span class="n">clear_ver</span><span class="o">=</span><span class="s2">&quot;32690&quot;</span> <span class="o">-</span><span class="n">t</span> <span class="n">dlrs</span><span class="o">-</span><span class="n">tensorflow</span><span class="o">-</span><span class="n">clearlinux</span><span class="p">:</span><span class="n">v0</span><span class="o">.</span><span class="mf">6.0</span> <span class="o">.</span>
</pre></div>
</div>
</section>
<section id="build-args">
<h2>Build ARGs<a class="headerlink" href="#build-args" title="Permalink to this headline"></a></h2>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">clear_ver</span></code> specifies the latest validated Clearlinux version for this DLRS Dockerfile.</p></li>
</ul>
<blockquote>
<div><p>NOTE: Changing this version may result in errors, if you want to upgrade the OS version, you should use <code class="docutils literal notranslate"><span class="pre">swupd_args</span></code> instead.</p>
</div></blockquote>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">swupd_args</span></code> specifies <a class="reference external" href="https://github.com/clearlinux/swupd-client/blob/master/docs/swupd.1.rst#options">swupd update</a> flags passed to the update during build.</p></li>
</ul>
<blockquote>
<div><p>NOTE: An empty <code class="docutils literal notranslate"><span class="pre">swupd_args</span></code> will default to 32690. Consider this when building as an OS upgrade won’t be performed. If you’d like to upgrade the OS version, you can either do it manually inside a running container or add <code class="docutils literal notranslate"><span class="pre">swupd_args=&quot;&lt;desired</span> <span class="pre">version&gt;&quot;</span></code> to the build command. The latest validated version is 32690, using a different one might result in unexpected errors.</p>
</div></blockquote>
</section>
<hr class="docutils" />
<section id="using-the-intel-openvino-model-optimizer">
<h2>Using the Intel® OpenVINO Model Optimizer<a class="headerlink" href="#using-the-intel-openvino-model-optimizer" title="Permalink to this headline"></a></h2>
<p>The Intel OpenVINO toolkit has two primary tools for Deep Learning, the inference engine and the model optimzer. The inference engine is integrated into the Deep Learning Reference Stack, however the model optimizer is better used separately post training before inference begins. This tutorial will explain how to use the model optimizer by going through a test case with a pre-trained TensorFlow model.</p>
<p>This guide will use resources found in the OpenVino Toolkit documentation. Original documentation is here:</p>
<p><a class="reference external" href="https://docs.openvinotoolkit.org/latest/_docs_MO_DG_prepare_model_convert_model_Convert_Model_From_TensorFlow.html">Converting a TensorFlow Model</a> - Where to download supported topologies</p>
<p><a class="reference external" href="https://docs.openvinotoolkit.org/latest/_docs_MO_DG_prepare_model_convert_model_tf_specific_Convert_Object_Detection_API_Models.html">Converting TensorFlow Object Detection API Models</a> - Instructions on converting specific models</p>
<section id="overview">
<h3>Overview<a class="headerlink" href="#overview" title="Permalink to this headline"></a></h3>
<p>In this tutorial, you will:</p>
<ol class="simple">
<li><p>Download a TensorFlow model</p></li>
<li><p>Clone the Model Optimizer</p></li>
<li><p>Install Prerequisites</p></li>
<li><p>Run the Model Optimizer</p></li>
</ol>
</section>
<section id="requirements">
<h3>Requirements<a class="headerlink" href="#requirements" title="Permalink to this headline"></a></h3>
<p>This tutorial assumes development on a linux OS with a terminal dev environment. The tutorial was tested in Ubuntu 18.04.2.</p>
</section>
<section id="download-a-tensorflow-model">
<h3>Download a TensorFlow model<a class="headerlink" href="#download-a-tensorflow-model" title="Permalink to this headline"></a></h3>
<p>We will be using an OpenVINO supported topology with the Model Optimizer. We will use a TensorFlow Inception V2 frozen model.</p>
<p>Navigate to the <a class="reference external" href="https://docs.openvinotoolkit.org/latest/_docs_MO_DG_prepare_model_convert_model_Convert_Model_From_TensorFlow.html">OpenVINO TensorFlow Model page.</a> Then scroll down to the second section titled “Supported Frozen Topologies from TensorFlow Object Detection Models Zoo” and download “SSD Inception V2 COCO.”</p>
<p>Unpack the file into your chosen working directory. For example, if the tar file is in your Downloads folder and you have navigated to the directory you want to extract it into, run:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">tar</span> <span class="o">-</span><span class="n">xvf</span> <span class="o">~/</span><span class="n">Downloads</span><span class="o">/</span><span class="n">ssd_inception_v2_coco_2018_01_28</span><span class="o">.</span><span class="n">tar</span><span class="o">.</span><span class="n">gz</span>
</pre></div>
</div>
</section>
<section id="clone-the-model-optimizer">
<h3>Clone the Model Optimizer<a class="headerlink" href="#clone-the-model-optimizer" title="Permalink to this headline"></a></h3>
<p>Next we need the model optimizer directory, named dldt, found <a class="reference external" href="https://github.com/opencv/dldt">here.</a> This guide will assume the parent directory is on the same level as the model directory, ie:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">.</span>
<span class="o">+--</span><span class="n">Working_Directory</span>
   <span class="o">+--</span> <span class="n">ssd_inception_v2_coco_2018_01_28</span>
   <span class="o">+--</span> <span class="n">dldt</span>
</pre></div>
</div>
<p>From inside the working directory:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">git</span> <span class="n">clone</span> <span class="n">https</span><span class="p">:</span><span class="o">//</span><span class="n">github</span><span class="o">.</span><span class="n">com</span><span class="o">/</span><span class="n">opencv</span><span class="o">/</span><span class="n">dldt</span><span class="o">.</span><span class="n">git</span>
</pre></div>
</div>
<p>If you explore the dldt directory, you’ll see both the inference engine and the model optimizer. We are only concerned with the model optimizer. Navigating into the model optimizer folder you’ll find several python scripts and text files. These are the scripts you call to run the model optimizer.</p>
</section>
<section id="install-prerequisites">
<h3>Install Prerequisites<a class="headerlink" href="#install-prerequisites" title="Permalink to this headline"></a></h3>
<p>Install the Python packages required to run the model optimizer by running the script dldt/model-optimizer/install_prerequisites/install_prerequisites_tf.sh.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">cd</span> <span class="n">dldt</span><span class="o">/</span><span class="n">model</span><span class="o">-</span><span class="n">optimizer</span><span class="o">/</span><span class="n">install_prerequisites</span><span class="o">/</span>
<span class="o">./</span><span class="n">install_prerequisites_tf</span><span class="o">.</span><span class="n">sh</span>
<span class="n">cd</span> <span class="o">../../..</span>
</pre></div>
</div>
</section>
<section id="run-the-model-optimizer">
<h3>Run the Model Optimizer<a class="headerlink" href="#run-the-model-optimizer" title="Permalink to this headline"></a></h3>
<p>Running the model optimizer is as simple as calling the appropriate script, however there are many configuration options that are explained <a class="reference external" href="https://docs.openvinotoolkit.org/latest/_docs_MO_DG_prepare_model_convert_model_tf_specific_Convert_Object_Detection_API_Models.html">here.</a></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">python</span> <span class="n">dldt</span><span class="o">/</span><span class="n">model</span><span class="o">-</span><span class="n">optimizer</span><span class="o">/</span><span class="n">mo_tf</span><span class="o">.</span><span class="n">py</span> \
<span class="o">--</span><span class="n">input_model</span><span class="o">=</span><span class="n">ssd_inception_v2_coco_2018_01_28</span><span class="o">/</span><span class="n">frozen_inference_graph</span><span class="o">.</span><span class="n">pb</span> \
<span class="o">--</span><span class="n">tensorflow_use_custom_operations_config</span> <span class="n">dldt</span><span class="o">/</span><span class="n">model</span><span class="o">-</span><span class="n">optimizer</span><span class="o">/</span><span class="n">extensions</span><span class="o">/</span><span class="n">front</span><span class="o">/</span><span class="n">tf</span><span class="o">/</span><span class="n">ssd_v2_support</span><span class="o">.</span><span class="n">json</span> \
<span class="o">--</span><span class="n">tensorflow_object_detection_api_pipeline_config</span> <span class="n">ssd_inception_v2_coco_2018_01_28</span><span class="o">/</span><span class="n">pipeline</span><span class="o">.</span><span class="n">config</span> \
<span class="o">--</span><span class="n">reverse_input_channels</span>
</pre></div>
</div>
<p>You should now see three files in your working directory, frozen_inference_graph.bin, frozen_inference_graph.mapping, and frozen_inference_graph.xml. These are your new models in the Intermediate Representation (IR) format and they are ready for use in the OpenVINO Inference Engine.</p>
</section>
</section>
<hr class="docutils" />
<section id="using-the-openvino-inference-engine">
<h2>Using the OpenVino Inference Engine<a class="headerlink" href="#using-the-openvino-inference-engine" title="Permalink to this headline"></a></h2>
<p>Basic example on how to run the inference engine on your local machine</p>
<section id="starting-the-model-server">
<h3>Starting the Model Server<a class="headerlink" href="#starting-the-model-server" title="Permalink to this headline"></a></h3>
<p>The process is similar to how we start <code class="docutils literal notranslate"><span class="pre">Jupter</span> <span class="pre">notebooks</span></code> on our containers</p>
<p>Run this command to spin up a OpenVino model fetched from GCP</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>docker run -p <span class="m">8000</span>:8000 stacks-tensorflow-mkl:latest bash -c <span class="s2">&quot;. /workspace/scripts/serve.sh &amp;&amp; ie_serving model --model_name resnet --model_path gs://public-artifacts/intelai_public_models/resnet_50_i8 --port 8000&quot;</span>
</pre></div>
</div>
<p>Once the server is setup, use a <code class="docutils literal notranslate"><span class="pre">grpc</span></code> client to communicate with served model, here is an example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">git</span> <span class="n">clone</span> <span class="n">https</span><span class="p">:</span><span class="o">//</span><span class="n">github</span><span class="o">.</span><span class="n">com</span><span class="o">/</span><span class="n">IntelAI</span><span class="o">/</span><span class="n">OpenVINO</span><span class="o">-</span><span class="n">model</span><span class="o">-</span><span class="n">server</span><span class="o">.</span><span class="n">git</span>
<span class="n">cd</span> <span class="n">OpenVINO</span><span class="o">-</span><span class="n">model</span><span class="o">-</span><span class="n">server</span>
<span class="n">pip</span> <span class="n">install</span> <span class="o">-</span><span class="n">q</span> <span class="o">-</span><span class="n">r</span> <span class="n">OpenVINO</span><span class="o">-</span><span class="n">model</span><span class="o">-</span><span class="n">server</span><span class="o">/</span><span class="n">example_client</span><span class="o">/</span><span class="n">client_requirements</span><span class="o">.</span><span class="n">txt</span>
<span class="n">pip</span> <span class="n">install</span> <span class="o">--</span><span class="n">user</span> <span class="o">-</span><span class="n">q</span> <span class="o">-</span><span class="n">r</span> <span class="n">OpenVINO</span><span class="o">-</span><span class="n">model</span><span class="o">-</span><span class="n">server</span><span class="o">/</span><span class="n">example_client</span><span class="o">/</span><span class="n">client_requirements</span><span class="o">.</span><span class="n">txt</span>
<span class="n">cat</span> <span class="n">OpenVINO</span><span class="o">-</span><span class="n">model</span><span class="o">-</span><span class="n">server</span><span class="o">/</span><span class="n">example_client</span><span class="o">/</span><span class="n">client_requirements</span><span class="o">.</span><span class="n">txt</span>
<span class="n">cd</span> <span class="n">OpenVINO</span><span class="o">-</span><span class="n">model</span><span class="o">-</span><span class="n">server</span><span class="o">/</span><span class="n">example_client</span>

<span class="n">python</span> <span class="n">jpeg_classification</span><span class="o">.</span><span class="n">py</span> <span class="o">--</span><span class="n">images_list</span> <span class="n">input_images</span><span class="o">.</span><span class="n">txt</span> <span class="o">--</span><span class="n">grpc_address</span> <span class="n">localhost</span> <span class="o">--</span><span class="n">grpc_port</span> <span class="mi">8000</span> <span class="o">--</span><span class="n">input_name</span> <span class="n">data</span> <span class="o">--</span><span class="n">output_name</span> <span class="n">prob</span> <span class="o">--</span><span class="n">size</span> <span class="mi">224</span> <span class="o">--</span><span class="n">model_name</span> <span class="n">resnet</span>
</pre></div>
</div>
<p>You should get an output like:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">start</span> <span class="n">processing</span><span class="p">:</span>
	<span class="n">Model</span> <span class="n">name</span><span class="p">:</span> <span class="n">resnet</span>
	<span class="n">Images</span> <span class="nb">list</span> <span class="n">file</span><span class="p">:</span> <span class="n">input_images</span><span class="o">.</span><span class="n">txt</span>
<span class="n">images</span><span class="o">/</span><span class="n">airliner</span><span class="o">.</span><span class="n">jpeg</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">224</span><span class="p">,</span> <span class="mi">224</span><span class="p">)</span> <span class="p">;</span> <span class="n">data</span> <span class="nb">range</span><span class="p">:</span> <span class="mf">0.0</span> <span class="p">:</span> <span class="mf">255.0</span>
<span class="n">Processing</span> <span class="n">time</span><span class="p">:</span> <span class="mf">97.00</span> <span class="n">ms</span><span class="p">;</span> <span class="n">speed</span> <span class="mf">2.00</span> <span class="n">fps</span> <span class="mf">10.35</span>
<span class="n">Detected</span><span class="p">:</span> <span class="mi">404</span>  <span class="n">Should</span> <span class="n">be</span><span class="p">:</span> <span class="mi">404</span>
<span class="n">images</span><span class="o">/</span><span class="n">arctic</span><span class="o">-</span><span class="n">fox</span><span class="o">.</span><span class="n">jpeg</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">224</span><span class="p">,</span> <span class="mi">224</span><span class="p">)</span> <span class="p">;</span> <span class="n">data</span> <span class="nb">range</span><span class="p">:</span> <span class="mf">0.0</span> <span class="p">:</span> <span class="mf">255.0</span>
<span class="n">Processing</span> <span class="n">time</span><span class="p">:</span> <span class="mf">16.00</span> <span class="n">ms</span><span class="p">;</span> <span class="n">speed</span> <span class="mf">2.00</span> <span class="n">fps</span> <span class="mf">63.89</span>
<span class="n">Detected</span><span class="p">:</span> <span class="mi">279</span>  <span class="n">Should</span> <span class="n">be</span><span class="p">:</span> <span class="mi">279</span>
<span class="n">images</span><span class="o">/</span><span class="n">bee</span><span class="o">.</span><span class="n">jpeg</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">224</span><span class="p">,</span> <span class="mi">224</span><span class="p">)</span> <span class="p">;</span> <span class="n">data</span> <span class="nb">range</span><span class="p">:</span> <span class="mf">0.0</span> <span class="p">:</span> <span class="mf">255.0</span>
<span class="n">Processing</span> <span class="n">time</span><span class="p">:</span> <span class="mf">14.00</span> <span class="n">ms</span><span class="p">;</span> <span class="n">speed</span> <span class="mf">2.00</span> <span class="n">fps</span> <span class="mf">69.82</span>
<span class="n">Detected</span><span class="p">:</span> <span class="mi">309</span>  <span class="n">Should</span> <span class="n">be</span><span class="p">:</span> <span class="mi">309</span>
<span class="n">images</span><span class="o">/</span><span class="n">golden_retriever</span><span class="o">.</span><span class="n">jpeg</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">224</span><span class="p">,</span> <span class="mi">224</span><span class="p">)</span> <span class="p">;</span> <span class="n">data</span> <span class="nb">range</span><span class="p">:</span> <span class="mf">0.0</span> <span class="p">:</span> <span class="mf">255.0</span>
<span class="n">Processing</span> <span class="n">time</span><span class="p">:</span> <span class="mf">13.00</span> <span class="n">ms</span><span class="p">;</span> <span class="n">speed</span> <span class="mf">2.00</span> <span class="n">fps</span> <span class="mf">75.22</span>
<span class="n">Detected</span><span class="p">:</span> <span class="mi">207</span>  <span class="n">Should</span> <span class="n">be</span><span class="p">:</span> <span class="mi">207</span>
<span class="n">images</span><span class="o">/</span><span class="n">gorilla</span><span class="o">.</span><span class="n">jpeg</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">224</span><span class="p">,</span> <span class="mi">224</span><span class="p">)</span> <span class="p">;</span> <span class="n">data</span> <span class="nb">range</span><span class="p">:</span> <span class="mf">0.0</span> <span class="p">:</span> <span class="mf">255.0</span>
<span class="n">Processing</span> <span class="n">time</span><span class="p">:</span> <span class="mf">11.00</span> <span class="n">ms</span><span class="p">;</span> <span class="n">speed</span> <span class="mf">2.00</span> <span class="n">fps</span> <span class="mf">87.24</span>
<span class="n">Detected</span><span class="p">:</span> <span class="mi">366</span>  <span class="n">Should</span> <span class="n">be</span><span class="p">:</span> <span class="mi">366</span>
<span class="n">images</span><span class="o">/</span><span class="n">magnetic_compass</span><span class="o">.</span><span class="n">jpeg</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">224</span><span class="p">,</span> <span class="mi">224</span><span class="p">)</span> <span class="p">;</span> <span class="n">data</span> <span class="nb">range</span><span class="p">:</span> <span class="mf">0.0</span> <span class="p">:</span> <span class="mf">247.0</span>
<span class="n">Processing</span> <span class="n">time</span><span class="p">:</span> <span class="mf">11.00</span> <span class="n">ms</span><span class="p">;</span> <span class="n">speed</span> <span class="mf">2.00</span> <span class="n">fps</span> <span class="mf">91.07</span>
<span class="n">Detected</span><span class="p">:</span> <span class="mi">635</span>  <span class="n">Should</span> <span class="n">be</span><span class="p">:</span> <span class="mi">635</span>
<span class="n">images</span><span class="o">/</span><span class="n">peacock</span><span class="o">.</span><span class="n">jpeg</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">224</span><span class="p">,</span> <span class="mi">224</span><span class="p">)</span> <span class="p">;</span> <span class="n">data</span> <span class="nb">range</span><span class="p">:</span> <span class="mf">0.0</span> <span class="p">:</span> <span class="mf">255.0</span>
<span class="n">Processing</span> <span class="n">time</span><span class="p">:</span> <span class="mf">9.00</span> <span class="n">ms</span><span class="p">;</span> <span class="n">speed</span> <span class="mf">2.00</span> <span class="n">fps</span> <span class="mf">110.1</span>
<span class="n">Detected</span><span class="p">:</span> <span class="mi">84</span>  <span class="n">Should</span> <span class="n">be</span><span class="p">:</span> <span class="mi">84</span>
<span class="n">images</span><span class="o">/</span><span class="n">pelican</span><span class="o">.</span><span class="n">jpeg</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">224</span><span class="p">,</span> <span class="mi">224</span><span class="p">)</span> <span class="p">;</span> <span class="n">data</span> <span class="nb">range</span><span class="p">:</span> <span class="mf">0.0</span> <span class="p">:</span> <span class="mf">255.0</span>
<span class="n">Processing</span> <span class="n">time</span><span class="p">:</span> <span class="mf">10.00</span> <span class="n">ms</span><span class="p">;</span> <span class="n">speed</span> <span class="mf">2.00</span> <span class="n">fps</span> <span class="mf">103.63</span>
<span class="n">Detected</span><span class="p">:</span> <span class="mi">144</span>  <span class="n">Should</span> <span class="n">be</span><span class="p">:</span> <span class="mi">144</span>
<span class="n">images</span><span class="o">/</span><span class="n">snail</span><span class="o">.</span><span class="n">jpeg</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">224</span><span class="p">,</span> <span class="mi">224</span><span class="p">)</span> <span class="p">;</span> <span class="n">data</span> <span class="nb">range</span><span class="p">:</span> <span class="mf">0.0</span> <span class="p">:</span> <span class="mf">248.0</span>
<span class="n">Processing</span> <span class="n">time</span><span class="p">:</span> <span class="mf">10.00</span> <span class="n">ms</span><span class="p">;</span> <span class="n">speed</span> <span class="mf">2.00</span> <span class="n">fps</span> <span class="mf">104.33</span>
<span class="n">Detected</span><span class="p">:</span> <span class="mi">113</span>  <span class="n">Should</span> <span class="n">be</span><span class="p">:</span> <span class="mi">113</span>
<span class="n">images</span><span class="o">/</span><span class="n">zebra</span><span class="o">.</span><span class="n">jpeg</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">224</span><span class="p">,</span> <span class="mi">224</span><span class="p">)</span> <span class="p">;</span> <span class="n">data</span> <span class="nb">range</span><span class="p">:</span> <span class="mf">0.0</span> <span class="p">:</span> <span class="mf">255.0</span>
<span class="n">Processing</span> <span class="n">time</span><span class="p">:</span> <span class="mf">12.00</span> <span class="n">ms</span><span class="p">;</span> <span class="n">speed</span> <span class="mf">2.00</span> <span class="n">fps</span> <span class="mf">83.04</span>
<span class="n">Detected</span><span class="p">:</span> <span class="mi">340</span>  <span class="n">Should</span> <span class="n">be</span><span class="p">:</span> <span class="mi">340</span>
<span class="n">Overall</span> <span class="n">accuracy</span><span class="o">=</span> <span class="mf">100.0</span> <span class="o">%</span>
<span class="n">Average</span> <span class="n">latency</span><span class="o">=</span> <span class="mf">19.8</span> <span class="n">ms</span>
</pre></div>
</div>
</section>
</section>
</section>


           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2020.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>